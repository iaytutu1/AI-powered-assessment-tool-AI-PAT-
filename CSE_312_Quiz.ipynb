{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FLIWfYJ3-yt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#ücretli\n",
        "client = OpenAI(\n",
        "    api_key=\"\",\n",
        "\n",
        ")\n",
        "\n",
        "#ücretsiz - testler için github api key oluştur\n",
        "# To authenticate with the model you will need to generate a personal access token (PAT) in your GitHub settings.\n",
        "# Create your PAT token by following instructions here: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens\n",
        "# from openai import OpenAI\n",
        "\n",
        "# client = OpenAI(\n",
        "#     base_url=\"https://models.inference.ai.azure.com\",\n",
        "#     api_key=\"\",\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "\n",
        "class EvaluationResponse(BaseModel):\n",
        "    evaluation_a: list[str]\n",
        "    grade_a: int\n",
        "    grades_each_criteria_a: list[int]\n",
        "\n",
        "    evaluation_b: list[str]\n",
        "    grade_b: int\n",
        "    grades_each_criteria_b: list[int]\n",
        "\n",
        "    totalGrade: int\n",
        "\n",
        "\n",
        "\n",
        "# print(response)"
      ],
      "metadata": {
        "id": "IV-qKjEI4MA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion_resformat(prompt_user, model=\"gpt-4o\", temperature=0.3, response_format = None):\n",
        "  response = client.beta.chat.completions.parse(\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"system\",\n",
        "              \"content\": \"You are a teaching assistant evaluating a student's answers about Operating Systems course for correctness and completeness.\"\n",
        "\n",
        "          },\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt_user,\n",
        "          }\n",
        "      ],\n",
        "      model=model,\n",
        "      temperature=temperature,\n",
        "      response_format = response_format\n",
        "  )\n",
        "\n",
        "  return response.choices[0].message.parsed"
      ],
      "metadata": {
        "id": "YvVUPFXN6BfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import openai\n",
        "import pandas as pd\n",
        "import os\n",
        "from time import sleep\n",
        "\n",
        "# Load students' answers from the file\n",
        "file_path = '/content/Quiz 2 Papers & Answers(1-147).xlsx'\n",
        "df = pd.read_excel(file_path, sheet_name = 'Sheet2')\n",
        "\n",
        "# Define the path to the prompts folder\n",
        "# script_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "prompts_dir = '/content/prompts/Quiz2'\n",
        "\n",
        "# Load the question and grading details from the prompts folder\n",
        "with open(os.path.join(prompts_dir, 'the_question.txt'), 'r') as f:\n",
        "    the_question = f.read()\n",
        "\n",
        "with open(os.path.join(prompts_dir, 'grading_prompt.txt'), 'r') as f:\n",
        "    grading_prompt = f.read()\n",
        "\n",
        "# Function to evaluate all parts of a student's answers in a single API call\n",
        "def evaluate_answers_combined(answers, temp_p = 0.3, model_p = \"gpt-4o\"):\n",
        "    # Combine answers for all parts into a single string\n",
        "\n",
        "    temperature = temp_p\n",
        "    model = model_p\n",
        "    answers_combined = f\"\"\"\n",
        "    Question 1a:\n",
        "    {answers['1a']}\n",
        "\n",
        "    Question 1b:\n",
        "    {answers['1b']}\n",
        "    \"\"\"\n",
        "\n",
        "    # Create the API prompt\n",
        "    prompt = grading_prompt.format(the_question) + \"\\n\\nStudent Answers:\\n\" + answers_combined\n",
        "    # print(prompt)\n",
        "\n",
        "\n",
        "    response = get_completion_resformat(prompt, model= model, temperature=temperature, response_format=EvaluationResponse)\n",
        "    # sleep(0.01)\n",
        "\n",
        "    # print(response)\n",
        "    # Extract the response text\n",
        "    evaluation_result = response\n",
        "\n",
        "\n",
        "\n",
        "    return evaluation_result\n"
      ],
      "metadata": {
        "id": "mW2yfdxc4kF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title Varsayılan başlık metni\n",
        "\n",
        "from google.colab import files\n",
        "# Define the temperatures and models you want to test\n",
        "\n",
        "temperatures = [0.0, 0.5]\n",
        "models = ['gpt-4o-mini', 'gpt-4o']  # use actual API model names\n",
        "\n",
        "# Process each student's answers\n",
        "results = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    print(\"row['STD_CODE']: {}\".format(row['STD_CODE']))\n",
        "    student = {\n",
        "        'Name': row['Name'],\n",
        "        'Email': row['Email'],\n",
        "        'STD_CODE': row['STD_CODE']\n",
        "    }\n",
        "\n",
        "    answers = {\n",
        "        '1a': row['Write the answer to PART A directly here. (You can copy the word)'],\n",
        "        '1b': row['Write the answer to PART B  directly here. (You can copy the word)']\n",
        "    }\n",
        "\n",
        "    result_entry = {\n",
        "        'Name': student['Name'],\n",
        "        'Email': student['Email'],\n",
        "        'STD_CODE': student['STD_CODE']\n",
        "    }\n",
        "\n",
        "    for model in models:\n",
        "        for temp_p in temperatures:\n",
        "            try:\n",
        "                evaluation_result = evaluate_answers_combined(answers, temp_p, model)\n",
        "\n",
        "                # Safe model name for column usage\n",
        "                model_safe = model.replace(\".\", \"\").replace(\"-\", \"\")\n",
        "                suffix = f\"_{temp_p}_{model_safe}\"\n",
        "\n",
        "                result_entry[f'Feedback_a{suffix}'] = evaluation_result.evaluation_a\n",
        "                result_entry[f'Grade_a{suffix}'] = evaluation_result.grade_a\n",
        "                result_entry[f'Feedback_b{suffix}'] = evaluation_result.evaluation_b\n",
        "                result_entry[f'Grade_b{suffix}'] = evaluation_result.grade_b\n",
        "                result_entry[f'Taken_grades_each_criteria_a{suffix}'] = evaluation_result.grades_each_criteria_a\n",
        "                result_entry[f'Taken_grades_each_criteria_b{suffix}'] = evaluation_result.grades_each_criteria_b\n",
        "                result_entry[f'Total_grade{suffix}'] = evaluation_result.totalGrade\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error evaluating {student['Name']} with {model} at temp {temp_p}: {e}\")\n",
        "                continue\n",
        "\n",
        "    results.append(result_entry)\n",
        "\n",
        "# Convert results to DataFrame and export\n",
        "results_df = pd.DataFrame(results)\n",
        "output_file = 'graded_students_answers_all_models_temps_Quiz2All.xlsx'\n",
        "results_df.to_excel(output_file, index=False)\n",
        "print(f\"Grading completed and saved to {output_file}.\")\n",
        "\n",
        "# Trigger file download\n",
        "files.download(output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "usJTc4FUOg-5",
        "outputId": "bf850423-2446-48ec-8fc1-6c47ceb1b03d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "row['STD_CODE']: 1000\n",
            "row['STD_CODE']: 1002\n",
            "row['STD_CODE']: 1004\n",
            "row['STD_CODE']: 1006\n",
            "row['STD_CODE']: 1008\n",
            "row['STD_CODE']: 1010\n",
            "row['STD_CODE']: 1012\n",
            "row['STD_CODE']: 1014\n",
            "row['STD_CODE']: 1016\n",
            "row['STD_CODE']: 1018\n",
            "row['STD_CODE']: 1020\n",
            "row['STD_CODE']: 1022\n",
            "row['STD_CODE']: 1024\n",
            "row['STD_CODE']: 1026\n",
            "row['STD_CODE']: 1028\n",
            "row['STD_CODE']: 1030\n",
            "row['STD_CODE']: 1032\n",
            "row['STD_CODE']: 1034\n",
            "row['STD_CODE']: 1036\n",
            "row['STD_CODE']: 1038\n",
            "row['STD_CODE']: 1040\n",
            "row['STD_CODE']: 1042\n",
            "row['STD_CODE']: 1044\n",
            "row['STD_CODE']: 1046\n",
            "row['STD_CODE']: 1048\n",
            "row['STD_CODE']: 1050\n",
            "row['STD_CODE']: 1052\n",
            "row['STD_CODE']: 1054\n",
            "row['STD_CODE']: 1056\n",
            "row['STD_CODE']: 1058\n",
            "row['STD_CODE']: 1060\n",
            "row['STD_CODE']: 1062\n",
            "row['STD_CODE']: 1064\n",
            "row['STD_CODE']: 1066\n",
            "row['STD_CODE']: 1068\n",
            "row['STD_CODE']: 1070\n",
            "row['STD_CODE']: 1072\n",
            "row['STD_CODE']: 1074\n",
            "row['STD_CODE']: 1076\n",
            "row['STD_CODE']: 1078\n",
            "row['STD_CODE']: 1080\n",
            "row['STD_CODE']: 1082\n",
            "row['STD_CODE']: 1084\n",
            "row['STD_CODE']: 1086\n",
            "row['STD_CODE']: 1088\n",
            "row['STD_CODE']: 1090\n",
            "row['STD_CODE']: 1092\n",
            "row['STD_CODE']: 1094\n",
            "row['STD_CODE']: 1096\n",
            "row['STD_CODE']: 1098\n",
            "row['STD_CODE']: 1100\n",
            "row['STD_CODE']: 1102\n",
            "row['STD_CODE']: 1104\n",
            "row['STD_CODE']: 1130\n",
            "row['STD_CODE']: 1132\n",
            "row['STD_CODE']: 1134\n",
            "row['STD_CODE']: 1136\n",
            "row['STD_CODE']: 1138\n",
            "row['STD_CODE']: 1140\n",
            "row['STD_CODE']: 1150\n",
            "row['STD_CODE']: 1152\n",
            "row['STD_CODE']: 1154\n",
            "row['STD_CODE']: 1156\n",
            "row['STD_CODE']: 1158\n",
            "row['STD_CODE']: 1160\n",
            "row['STD_CODE']: 1162\n",
            "row['STD_CODE']: 1164\n",
            "row['STD_CODE']: 1166\n",
            "row['STD_CODE']: 1168\n",
            "row['STD_CODE']: 1172\n",
            "row['STD_CODE']: 1174\n",
            "row['STD_CODE']: 1176\n",
            "row['STD_CODE']: 1178\n",
            "row['STD_CODE']: 1182\n",
            "row['STD_CODE']: 1184\n",
            "row['STD_CODE']: 1186\n",
            "row['STD_CODE']: 1188\n",
            "row['STD_CODE']: 1190\n",
            "row['STD_CODE']: 1192\n",
            "row['STD_CODE']: 1194\n",
            "row['STD_CODE']: 1196\n",
            "row['STD_CODE']: 1198\n",
            "row['STD_CODE']: 1200\n",
            "row['STD_CODE']: 1202\n",
            "row['STD_CODE']: 1204\n",
            "row['STD_CODE']: 1206\n",
            "row['STD_CODE']: 1208\n",
            "row['STD_CODE']: 1210\n",
            "row['STD_CODE']: 1212\n",
            "row['STD_CODE']: 1214\n",
            "row['STD_CODE']: 1228\n",
            "row['STD_CODE']: 1230\n",
            "row['STD_CODE']: 1240\n",
            "row['STD_CODE']: 1242\n",
            "row['STD_CODE']: 1244\n",
            "row['STD_CODE']: 1246\n",
            "row['STD_CODE']: 1248\n",
            "row['STD_CODE']: 1250\n",
            "row['STD_CODE']: 1252\n",
            "row['STD_CODE']: 1254\n",
            "row['STD_CODE']: 1256\n",
            "row['STD_CODE']: 1292\n",
            "row['STD_CODE']: 1294\n",
            "row['STD_CODE']: 1296\n",
            "row['STD_CODE']: 1298\n",
            "row['STD_CODE']: 1300\n",
            "row['STD_CODE']: 1304\n",
            "row['STD_CODE']: 1306\n",
            "row['STD_CODE']: 1308\n",
            "row['STD_CODE']: 1310\n",
            "row['STD_CODE']: 1312\n",
            "row['STD_CODE']: 1314\n",
            "row['STD_CODE']: 1316\n",
            "row['STD_CODE']: 1318\n",
            "row['STD_CODE']: 1320\n",
            "row['STD_CODE']: 1322\n",
            "row['STD_CODE']: 1324\n",
            "row['STD_CODE']: 1326\n",
            "row['STD_CODE']: 1328\n",
            "row['STD_CODE']: 1330\n",
            "row['STD_CODE']: 1332\n",
            "row['STD_CODE']: 1334\n",
            "row['STD_CODE']: 1336\n",
            "row['STD_CODE']: 1338\n",
            "row['STD_CODE']: 1340\n",
            "row['STD_CODE']: 1342\n",
            "row['STD_CODE']: 1344\n",
            "row['STD_CODE']: 1346\n",
            "row['STD_CODE']: 1348\n",
            "row['STD_CODE']: 1350\n",
            "row['STD_CODE']: 1352\n",
            "row['STD_CODE']: 1354\n",
            "row['STD_CODE']: 1356\n",
            "row['STD_CODE']: 1358\n",
            "row['STD_CODE']: 1360\n",
            "row['STD_CODE']: 1362\n",
            "row['STD_CODE']: 1364\n",
            "row['STD_CODE']: 1366\n",
            "row['STD_CODE']: 1368\n",
            "row['STD_CODE']: 1370\n",
            "row['STD_CODE']: 1372\n",
            "row['STD_CODE']: 1374\n",
            "row['STD_CODE']: 1378\n",
            "row['STD_CODE']: 1380\n",
            "row['STD_CODE']: 1382\n",
            "row['STD_CODE']: 1384\n",
            "row['STD_CODE']: 1386\n",
            "Grading completed and saved to graded_students_answers_all_models_temps_Quiz2All.xlsx.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b714d425-1b6a-464d-8b80-a421fbf6b63f\", \"graded_students_answers_all_models_temps_Quiz2All.xlsx\", 114820)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}